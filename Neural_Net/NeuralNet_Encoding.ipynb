{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training and test corpus\n",
    "df_train = pd.read_csv('../kaggle-competition-2/train_data.csv')\n",
    "df_test = pd.read_csv('../kaggle-competition-2/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    sentences = df.copy()\n",
    "    # Converting all the upper case to lower case to avoid the distinction between them\n",
    "    sentences['text'] = df['text'].str.lower()\n",
    "    # Putting the regex for removing the https and www URLs\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))\n",
    "\n",
    "    # Remove the video and links\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r'{link}', '', x))\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r\"\\[video\\]\", '', x))\n",
    "\n",
    "    # Remove html reference characters\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
    "\n",
    "    # Remove usernames\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r'@[^\\s]+', '', x))\n",
    "\n",
    "    # Removing numbers\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "    # Removing hashmarks, non-letter characters\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', x))\n",
    "\n",
    "    # Removing all extra same letters to a limit of 2, ex. daaaang => daang, nooooooo => noo\n",
    "    sentences['text'] = sentences['text'].apply(lambda x: re.sub(r\"(.)\\1+\", r\"\\1\\1\", x))\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the senteces \n",
    "train_proc = preprocessing(df_train)\n",
    "test_proc = preprocessing(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the encoder corpus\n",
    "enc_corp = pd.concat([train_proc['text'],test_proc['text']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec : CBOW and SkipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [anyway, im, getting, of, for, a, while, ]\n",
       "1    [my, red, apache, isn't, feelin, too, well, th...\n",
       "2    [, you, should, be, , its, great, friday, will...\n",
       "3    [its, :pm, and, i, dont, wanna, sleep;, so, i,...\n",
       "4    [why, does, twitter, eat, my, dm's, , not, hap...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform sentences to list of words\n",
    "sentences_corp = enc_corp.apply(lambda x: x.split(' '))\n",
    "sentences_corp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Word2Vec encoding with Skip-Gram and vector size of 100\n",
    "word2vec_SkipGram_100d = Word2Vec(sentences=sentences_corp, sg=1, vector_size=100, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Word2Vec encoding with Skip-Gram and vector size of 300\n",
    "word2vec_SkipGram_300d = Word2Vec(sentences=sentences_corp, sg=1, vector_size=300, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Word2Vec encoding with Skip-Gram and vector size of 100\n",
    "word2vec_CBOW_100d = Word2Vec(sentences=sentences_corp, sg=0, vector_size=100, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Word2Vec encoding with Skip-Gram and vector size of 300\n",
    "word2vec_CBOW_300d = Word2Vec(sentences=sentences_corp, sg=0, vector_size=300, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58064\n",
      "58064\n",
      "58064\n",
      "58064\n"
     ]
    }
   ],
   "source": [
    "#Test our encoding\n",
    "print(len(list(word2vec_SkipGram_100d.wv.index_to_key)))\n",
    "print(len(list(word2vec_CBOW_100d.wv.index_to_key)))\n",
    "print(len(list(word2vec_SkipGram_300d.wv.index_to_key)))\n",
    "print(len(list(word2vec_CBOW_300d.wv.index_to_key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('laptop', 0.8989043831825256), ('pc', 0.8486779928207397), ('comp', 0.8269506096839905), ('lappy', 0.795569658279419), ('compy', 0.7851570248603821), ('hiptop', 0.7809572815895081), (\"computer's\", 0.7777619361877441), ('lappie', 0.7758223414421082), ('crackberry', 0.7602812051773071), (\"'puter\", 0.7577412128448486)]\n",
      "[('laptop', 0.7389435768127441), ('pc', 0.7175706624984741), ('comp', 0.7175503373146057), ('hiptop', 0.625059962272644), ('lappy', 0.6205175518989563), ('compy', 0.6123674511909485), ('lappie', 0.6052822470664978), (\"ipod's\", 0.6034489274024963), ('puter', 0.596084475517273), ('crackberry', 0.5949008464813232)]\n"
     ]
    }
   ],
   "source": [
    "#Find words similar to computer\n",
    "#We can see that the 300d vector seems less accurate\n",
    "print(word2vec_SkipGram_100d.wv.most_similar('computer'))\n",
    "print(word2vec_SkipGram_300d.wv.most_similar('computer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('laptop', 0.9023221135139465), ('pc', 0.8601002097129822), ('comp', 0.8528246879577637), ('internet', 0.7690550088882446), ('lappy', 0.7540048360824585), ('phone', 0.7529410123825073), ('cellphone', 0.733026385307312), ('crackberry', 0.7199079394340515), ('keyboard', 0.7187231183052063), ('blackberry', 0.7149540185928345)]\n",
      "[('laptop', 0.8617371916770935), ('comp', 0.8138261437416077), ('pc', 0.8056346774101257), ('lappy', 0.6895983219146729), ('keyboard', 0.6700029969215393), ('internet', 0.6550202965736389), ('router', 0.6546667814254761), ('cellphone', 0.6490676403045654), ('phone', 0.6462036967277527), ('ipod', 0.6435583233833313)]\n"
     ]
    }
   ],
   "source": [
    "#Find words similar to computer\n",
    "#Once again the 300d vector seems less accurate\n",
    "print(word2vec_CBOW_100d.wv.most_similar('computer'))\n",
    "print(word2vec_CBOW_300d.wv.most_similar('computer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the models\n",
    "word2vec_SkipGram_100d.save('../Encoders/word2vec_SkipGram_100d')\n",
    "word2vec_CBOW_100d.save('../Encoders/word2vec_CBOW_100d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('laptop', 0.9023221135139465),\n",
       " ('pc', 0.8601002097129822),\n",
       " ('comp', 0.8528246879577637),\n",
       " ('internet', 0.7690550088882446),\n",
       " ('lappy', 0.7540048360824585),\n",
       " ('phone', 0.7529410123825073),\n",
       " ('cellphone', 0.733026385307312),\n",
       " ('crackberry', 0.7199079394340515),\n",
       " ('keyboard', 0.7187231183052063),\n",
       " ('blackberry', 0.7149540185928345)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of loading model\n",
    "new_model = Word2Vec.load('../Encoders/word2vec_CBOW_100d')\n",
    "new_model.wv.most_similar('computer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05d8f42d34e97b63e1918e352e5e1ee86173089fb3b8c3e567ea1c06d83cd6aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
